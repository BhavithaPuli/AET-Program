# School Enrollment & Education Performance Analytics Platform

## ğŸ“Œ Project Overview
This project implements an **end-to-end Education Analytics Platform** designed to analyze school enrollment and performance data.  
The system follows a **modern ETL architecture** using **Azure Databricks (Serverless)** for data processing, **Airflow** for orchestration, and **Power BI** for visualization.

The platform enables stakeholders to monitor enrollment trends, evaluate school performance, compare targets vs actuals, and support data-driven decision-making.


## ğŸ¯ Objectives
- Build a scalable ETL pipeline for education enrollment data
- Clean and standardize raw datasets
- Generate analytics-ready **Gold tables**
- Automate workflows using **Airflow**
- Visualize insights using **Power BI dashboards**


## ğŸ› ï¸ Technology Stack
- **Python**
- **Pandas** (analytics & validation)
- **PySpark**
- **Azure Databricks (Serverless Compute)**
- **Delta Lake**
- **Apache Airflow**
- **Power BI**
- **GitHub**


## ğŸ—ï¸ Architecture Overview
The project follows a **Bronzeâ€“Silverâ€“Gold ETL architecture**:

### ğŸ”¹ Bronze Layer (Raw Data)
- Ingests multiple raw enrollment CSV files
- Stores combined raw data as Delta tables

### ğŸ”¹ Silver Layer (Cleaned Data)
- Handles missing values and inconsistencies
- Standardizes schema and data types
- Produces cleaned Delta tables

### ğŸ”¹ Gold Layer (Analytics)
- Aggregated and business-ready datasets
- Optimized for reporting and dashboards
- Used directly by Power BI


## ğŸ”„ ETL Workflow
### 1ï¸âƒ£ Extract
- Read enrollment datasets from Databricks storage
- Load raw data into Bronze Delta tables

### 2ï¸âƒ£ Transform
- Data cleaning and validation
- Feature engineering and metric calculations
- Composite metrics such as **school_score**

### 3ï¸âƒ£ Load
- Write transformed data into Silver and Gold Delta tables
- Make analytics tables available for visualization

ğŸ“Œ **Note:**  
ETL scripts are implemented as **Python-based Databricks notebooks**, which is a standard practice for Spark ETL pipelines.


## ğŸ“Š Analytics & KPIs
The Gold layer includes analytics such as:
- Year-wise enrollment trends
- Gender-wise and grade-wise enrollment distribution
- District and school-level performance comparison
- Pass rate and attendance analysis
- Learning growth and skill index metrics
- Composite school performance score
- Ranking of schools (overall and district-wise)
- Target vs actual enrollment analysis (500M annual target)

## â±ï¸ Workflow Orchestration - Airflow
An Apache Airflow DAG orchestrates the pipeline with:
  Weekly scheduling
  Retry logic and fault tolerance
  Sequential execution:
    Data Ingestion (Bronze)
    Data Cleaning (Silver)
    Analytics & Gold table generation
    Power BI refresh (simulated)

Airflow triggers **Azure Databricks Serverless Jobs** using a secure **Personal Access Token (PAT)**.


## ğŸ“ˆ Power BI Dashboards
Power BI dashboards are built using Gold tables and include:
KPI visual showing **Target vs Achieved Enrollment**
Enrollment trends over time
Gender and grade distribution
District-wise performance insights
School ranking visuals


## ğŸ“ Repository Structure
'''text
Capstone Project/
â”œâ”€â”€ Airflow/
â”‚   â”œâ”€â”€ capstone.py
â”‚   â”œâ”€â”€ Enrollment_Education_Analytics_Pipeline-graph.png
â”‚   â”œâ”€â”€ school_enrollment_education_pipeline-graph.png
â”‚   â””â”€â”€ Integration_of_DataBricks_with_Airflow.jpg
â”‚
â”œâ”€â”€ Notebooks/
â”‚   â”œâ”€â”€ Data Ingestion.ipynb
â”‚   â”œâ”€â”€ Data Cleaning Transformation.ipynb
â”‚   â””â”€â”€ Data Analytics.ipynb
â”‚
â”œâ”€â”€ Datasets/
â”‚   â””â”€â”€ raw_enrollment_files.csv
â”‚
â”œâ”€â”€ Power BI/
â”‚   â””â”€â”€ enrollment_dashboard.pbix
â”‚
â”œâ”€â”€ Presentation/
â”‚   â””â”€â”€ Final_Project_Presentation.pptx
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
'''
        


## ğŸš€ How to Run the Project
1. Upload raw datasets to Databricks storage
2. Execute Databricks notebooks in order:
   - Ingestion â†’ Cleaning â†’ Analytics
3. Create Databricks Jobs using **Serverless Compute**
4. Update Job IDs in the Airflow DAG
5. Trigger the Airflow DAG (weekly or manual)
6. Connect Power BI to Gold Delta tables



## ğŸ§  Key Learnings
- Building scalable ETL pipelines using Spark and Delta Lake
- Automating workflows with Airflow
- Designing analytics-ready data models
- Creating business-focused dashboards in Power BI
- Working with Azure Databricks Serverless architecture



## âœ… Project Status
âœ” ETL pipeline implemented  
âœ” Analytics and Gold tables completed  
âœ” Airflow orchestration completed  
âœ” Power BI dashboards created  
âœ” Documentation completed  


## ğŸ“Œ Note
This project is developed as part of an academic capstone and demonstrates real-world data engineering and analytics practice
