{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5017d45f-56ad-4f9c-9c15-5db00b8f8614",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80054a67-03be-4f6b-a69e-2fb96aed423f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark_df = spark.table(\"school_enrollment_db.cleaned_school_enrollment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73bfa037-fdb2-4896-b96c-72c31d5c0dcf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+------+---------------+-------------+-----+------+-----------------+-----------------+---------------+---------------+---------------------+-------------------+-----------------+---------------+----------------------+------------------+-----------------------+-------------------+---------------------+-------------------------+----------------------+-----------------+-----------+\n|   school_id|         school_name|  city|       district|academic_year|grade|gender|enrolled_students|   avg_exam_score|pass_percentage|attendance_rate|learning_growth_index|        source_file|median_exam_score|fail_percentage|distinction_percentage|avg_internal_score|exam_participation_rate|remedial_percentage|student_teacher_ratio|digital_access_percentage|scholarship_percentage|subject_pass_rate|skill_index|\n+------------+--------------------+------+---------------+-------------+-----+------+-----------------+-----------------+---------------+---------------+---------------------+-------------------+-----------------+---------------+----------------------+------------------+-----------------------+-------------------+---------------------+-------------------------+----------------------+-----------------+-----------+\n|IND_SCH_0018|Municipal Corpora...|Mumbai|Mumbai Suburban|         2023|    5|  Male|             23.0|75.29013452914798|           66.6|           92.4|                 0.77|enrollment_2023.csv|             84.6|           33.4|                  18.0|              76.2|                   84.8|               17.7|                 25.5|                     59.4|                  34.3|             66.0|       36.5|\n|IND_SCH_0018|Municipal Corpora...|Mumbai|Mumbai Suburban|         2023|    5|Female|            100.0|             58.2|           96.1|           89.7|                 0.86|enrollment_2023.csv|             76.2|            3.9|                  32.9|              83.8|                   81.5|               19.1|                 16.4|                     63.7|                  62.9|             66.4|       36.4|\n|IND_SCH_0018|Municipal Corpora...|Mumbai|Mumbai Suburban|         2023|    5|  Male|            110.0|75.29013452914798|           84.7|           99.2|                 0.72|enrollment_2023.csv|             82.9|           15.3|                  16.8|              52.1|                   78.4|               26.7|                 26.6|                     72.4|                  36.0|             91.8|       59.8|\n|IND_SCH_0018|Municipal Corpora...|Mumbai|Mumbai Suburban|         2023|    6|  Male|             95.0|             68.9|           94.2|           77.6|                 0.35|enrollment_2023.csv|             94.9|            5.8|                   8.8|              50.4|                   86.3|               25.9|                 44.9|                     87.3|                  42.5|             67.5|       42.0|\n|IND_SCH_0018|Municipal Corpora...|Mumbai|Mumbai Suburban|         2023|    6|Female|            173.0|             73.5|           73.8|           88.8|                 0.72|enrollment_2023.csv|             63.0|           26.2|                  30.2|              87.1|                   91.3|                6.9|                 28.5|                     44.3|                  57.4|             74.4|       60.6|\n+------------+--------------------+------+---------------+-------------+-----+------+-----------------+-----------------+---------------+---------------+---------------------+-------------------+-----------------+---------------+----------------------+------------------+-----------------------+-------------------+---------------------+-------------------------+----------------------+-----------------+-----------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "spark_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdc1db98-6007-47cf-871a-4f6814ef5bd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def printSparkResult(df, title, n=20):\n",
    "    # Prints the title for the Spark DataFrame output\n",
    "    print(f\"\\n{title}\")  \n",
    "    # Displays the top `n` rows of the Spark DataFrame without truncating column values          \n",
    "    df.show(n, truncate=False)       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4f7c005-8868-4249-9c4a-d1f4777a34d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Year wise Enrollment Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d21384ce-af72-4e55-9c75-98f6a5af7fd4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nYear wise Enrollment Trend\n+-------------+----------------+\n|academic_year|total_enrollment|\n+-------------+----------------+\n|2020         |831474.5        |\n|2021         |834422.5        |\n|2022         |824672.5        |\n|2023         |825296.0        |\n|2024         |832112.0        |\n+-------------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum as spark_sum\n",
    "# Group the data by academic year, calculate total enrollment, and sort by year\n",
    "yearly_enrollment = (\n",
    "    # Group records based on academic year\n",
    "    spark_df\n",
    "    .groupBy(\"academic_year\")\n",
    "    # Aggregate total enrolled students for each academic year\n",
    "    .agg(\n",
    "        spark_sum(\"enrolled_students\").alias(\"total_enrollment\")\n",
    "    )\n",
    "    # Order the result by academic year for trend analysis\n",
    "    .orderBy(\"academic_year\")\n",
    ")\n",
    "printSparkResult(yearly_enrollment, \"Year wise Enrollment Trend\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b7c078c-0050-40e2-83ef-0e646dc59d37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Gender wise Enrollment Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2bcb7b6-d0e4-4545-aff5-38ee75cbd8c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nGender wise Enrollment Distribution\n+------+----------------+\n|gender|total_enrollment|\n+------+----------------+\n|Male  |2494890.0       |\n|Female|1653087.5       |\n+------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Group the data by gender and calculate total enrollment for each gender\n",
    "gender_enrollment = (\n",
    "    spark_df\n",
    "    .groupBy(\"gender\")    \n",
    "    # Aggregate total enrolled students for each gender\n",
    "    .agg(\n",
    "        spark_sum(\"enrolled_students\").alias(\"total_enrollment\")\n",
    "    )\n",
    ")\n",
    "printSparkResult(gender_enrollment, \"Gender wise Enrollment Distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe91ad27-35cf-4062-a66b-91fe0665db0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Grade Level Enrollment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c5e51fb-9cb5-4585-aa06-8f26d80dfdc1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nGrade Level Enrollment\n+-----+----------------+\n|grade|total_enrollment|\n+-----+----------------+\n|1    |339056.0        |\n|2    |346081.0        |\n|3    |346966.0        |\n|4    |345384.0        |\n|5    |343651.0        |\n|6    |350771.0        |\n|7    |339795.0        |\n|8    |350540.0        |\n|9    |352377.0        |\n|10   |346221.0        |\n|11   |343267.0        |\n|12   |343868.5        |\n+-----+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Group the data by grade level, calculate total enrollment, and sort by grade\n",
    "grade_enrollment = (\n",
    "    spark_df\n",
    "    .groupBy(\"grade\")\n",
    "    # Aggregate total enrolled students for each grade\n",
    "    .agg(\n",
    "        spark_sum(\"enrolled_students\").alias(\"total_enrollment\")\n",
    "    )\n",
    "    # Order the results by grade level\n",
    "    .orderBy(\"grade\")\n",
    ")\n",
    "printSparkResult(grade_enrollment, \"Grade Level Enrollment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fea5aa66-17bd-4275-8358-5d5c23d30474",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "District wise Enrollment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36f699ac-de57-43a1-927a-2e3abaea690a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nDistrict wise Enrollment\n+-----------------+----------------+\n|district         |total_enrollment|\n+-----------------+----------------+\n|Raigad Rural     |864772.5        |\n|New Delhi        |445210.5        |\n|Chennai          |360338.0        |\n|Bangalore Urban  |331399.5        |\n|Mumbai Suburban  |327441.5        |\n|Pune Rural       |297453.5        |\n|Lucknow Rural    |272352.5        |\n|Ranga Reddy      |267309.0        |\n|Ahmedabad Rural  |266854.5        |\n|Bangalore Rural  |239153.5        |\n|North 24 Parganas|208235.0        |\n|Jaipur Urban     |146737.5        |\n|Pune Urban       |120720.0        |\n+-----------------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Group the data by district, calculate total enrollment, and sort by highest enrollment first\n",
    "district_enrollment = (\n",
    "    spark_df\n",
    "    .groupBy(\"district\")\n",
    "    # Aggregate total enrolled students for each district\n",
    "    .agg(\n",
    "        spark_sum(\"enrolled_students\").alias(\"total_enrollment\")\n",
    "    )\n",
    "    # Order districts by total enrollment in descending order\n",
    "    .orderBy(\"total_enrollment\", ascending=False)\n",
    ")\n",
    "printSparkResult(district_enrollment, \"District wise Enrollment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51e0621c-c960-4ed1-ac60-6e33a983165e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Average Score by Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b053186e-82d2-4d18-a4d8-95ec9e550edd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nAverage Exam Score by Year\n+-------------+-----------------+\n|academic_year|avg_exam_score   |\n+-------------+-----------------+\n|2020         |74.23961309074657|\n|2021         |74.45818389332263|\n|2022         |74.46198580937349|\n|2023         |74.18933385436154|\n|2024         |74.40807421986436|\n+-------------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Group the data by academic year, calculate the average exam score, and sort the results by year\n",
    "avgscore_year = (\n",
    "    spark_df\n",
    "    .groupBy(\"academic_year\")\n",
    "    # Compute the average exam score for each academic year\n",
    "    .agg(\n",
    "        avg(\"avg_exam_score\").alias(\"avg_exam_score\")\n",
    "    )\n",
    "    # Order the output by academic year\n",
    "    .orderBy(\"academic_year\")\n",
    ")\n",
    "printSparkResult(avgscore_year, \"Average Exam Score by Year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ef106d5-4568-4cb4-aae9-b5adba939ebe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Pass Rate by District"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b877e58-4fd6-474b-8d8c-49ac7a877d2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nPass Rate by District\n+-----------------+-----------------+\n|district         |avg_pass_rate    |\n+-----------------+-----------------+\n|North 24 Parganas|81.9179523809524 |\n|Lucknow Rural    |81.77051851851844|\n|Ranga Reddy      |81.59799999999973|\n|Jaipur Urban     |81.56959999999998|\n|Bangalore Urban  |81.5166363636364 |\n|Ahmedabad Rural  |81.51437037037005|\n|Pune Urban       |81.49633333333337|\n|Bangalore Rural  |81.4654583333334 |\n|Chennai          |81.46480555555551|\n|Raigad Rural     |81.44547126436768|\n|New Delhi        |81.33580000000023|\n|Mumbai Suburban  |81.21784848484869|\n|Pune Rural       |81.09099999999991|\n+-----------------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Group the data by district, calculate the average pass rate, and sort by highest pass rate\n",
    "passrate_district = (\n",
    "    spark_df\n",
    "    .groupBy(\"district\")\n",
    "    # Compute the average pass percentage for each district\n",
    "    .agg(\n",
    "        avg(\"pass_percentage\").alias(\"avg_pass_rate\")\n",
    "    )\n",
    "    # Order districts by average pass rate in descending order\n",
    "    .orderBy(\"avg_pass_rate\", ascending=False)\n",
    ")\n",
    "printSparkResult(passrate_district, \"Pass Rate by District\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be9c5d63-44f6-4423-a2af-f3d3b25497ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Attendance vs Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfba4c5f-c330-44f9-9808-8ad461ac50b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nAttendance vs Performance\n+-----------------+-----------------+-----------------+\n|district         |avg_attendance   |avg_exam_score   |\n+-----------------+-----------------+-----------------+\n|Mumbai Suburban  |85.05196969696979|73.86800156832608|\n|Lucknow Rural    |85.09100000000011|74.29948865791057|\n|Pune Rural       |84.87370000000008|74.36627079470499|\n|Raigad Rural     |85.10868965517223|74.32300193916949|\n|New Delhi        |84.88033333333318|74.24764656372902|\n|Bangalore Urban  |85.18836363636377|74.32613476269252|\n|Ranga Reddy      |85.12433333333323|74.62764945714149|\n|Chennai          |84.82261111111113|74.92851851336323|\n|Bangalore Rural  |84.84958333333324|74.10615743529803|\n|Jaipur Urban     |85.34006666666669|74.30500966987076|\n|Ahmedabad Rural  |85.17011111111134|74.15630793985946|\n|North 24 Parganas|85.03314285714292|74.52911778133698|\n|Pune Urban       |85.2880833333334 |74.7496437213605 |\n+-----------------+-----------------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Group the data by district to analyze attendance and academic performance together\n",
    "attendance_perf = (\n",
    "    spark_df\n",
    "    .groupBy(\"district\")    \n",
    "    # Calculate average attendance rate and average exam score for each district\n",
    "    .agg(\n",
    "        avg(\"attendance_rate\").alias(\"avg_attendance\"),\n",
    "        avg(\"avg_exam_score\").alias(\"avg_exam_score\")\n",
    "    )\n",
    ")\n",
    "printSparkResult(attendance_perf, \"Attendance vs Performance\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4e4e2c2-bdec-4f5b-918f-b34cfb7e786f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Year wise Learning Growth Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b42bdc86-70c0-4564-b367-19a6a51cf768",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nLearning Growth Trend\n+-------------+-------------------+\n|academic_year|avg_learning_growth|\n+-------------+-------------------+\n|2020         |0.5009100719424461 |\n|2021         |0.5047865707434069 |\n|2022         |0.5016342925659476 |\n|2023         |0.5004808153477209 |\n|2024         |0.4983441247002392 |\n+-------------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Group the data by academic year to analyze learning growth over time\n",
    "learning_growth = (\n",
    "    spark_df\n",
    "    .groupBy(\"academic_year\")    \n",
    "    # Calculate the average learning growth index for each academic year\n",
    "    .agg(\n",
    "        avg(\"learning_growth_index\").alias(\"avg_learning_growth\")\n",
    "    )\n",
    "    # Order the results by academic year to observe trends\n",
    "    .orderBy(\"academic_year\")\n",
    ")\n",
    "printSparkResult(learning_growth, \"Learning Growth Trend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2aa4fc63-bfbc-4553-80e1-4fa359890ccd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Skill Index by District"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4917952-2c5f-4ead-a3b9-edf04fd5d14a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nSkill Index by District\n+-----------------+-----------------+\n|district         |avg_skill_index  |\n+-----------------+-----------------+\n|Lucknow Rural    |65.19377777777781|\n|Pune Rural       |65.15149999999993|\n|Jaipur Urban     |65.12566666666663|\n|Bangalore Rural  |65.06308333333325|\n|Ahmedabad Rural  |65.03396296296286|\n|New Delhi        |64.98637777777803|\n|Bangalore Urban  |64.88509090909096|\n|Raigad Rural     |64.85219540229829|\n|Mumbai Suburban  |64.8146363636364 |\n|North 24 Parganas|64.74528571428577|\n|Pune Urban       |64.7398333333333 |\n|Chennai          |64.70258333333328|\n|Ranga Reddy      |64.2905185185185 |\n+-----------------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Group the data by district to evaluate skill levels across regions\n",
    "skill_district = (\n",
    "    spark_df\n",
    "    .groupBy(\"district\")\n",
    "    # Calculate the average skill index for each district\n",
    "    .agg(\n",
    "        avg(\"skill_index\").alias(\"avg_skill_index\")\n",
    "    )    \n",
    "    # Order districts by average skill index in descending order\n",
    "    .orderBy(\"avg_skill_index\", ascending=False)\n",
    ")\n",
    "printSparkResult(skill_district, \"Skill Index by District\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee8b3489-2742-4340-8307-89948bfe9ee1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"USE school_enrollment_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a63ab75-3131-45a9-974d-d562108b789c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "# Write yearly enrollment aggregation to a Delta table\n",
    "yearly_enrollment.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"`yearly_enrollment`\")\n",
    "# Write gender-wise enrollment aggregation to a Delta table\n",
    "gender_enrollment.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"`gender_enrollment`\")\n",
    "# Write grade-level enrollment aggregation to a Delta table\n",
    "grade_enrollment.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"`grade_enrollment`\")\n",
    "# Write district-wise enrollment aggregation to a Delta table\n",
    "district_enrollment.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"`district_enrollment`\")\n",
    "# Write average exam score by academic year to a Delta table\n",
    "avgscore_year.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"`average_score_by_year`\")\n",
    "# Write average pass rate by district to a Delta table\n",
    "passrate_district.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"`pass_rate_by_district`\")\n",
    "# Write attendance versus performance analysis to a Delta table\n",
    "attendance_perf.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"`attendance_vs_performance`\")\n",
    "# Write learning growth trend by academic year to a Delta table\n",
    "learning_growth.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"`learning_growth_by_year`\")\n",
    "# Write skill index analysis by district to a Delta table\n",
    "skill_district.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"`skill_index_by_district`\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "898c7018-e1a5-44a5-9cbc-ea3bc0758885",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "School Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91581044-4f2f-488b-bdcf-a6538c9ef13e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "# Aggregate school-level performance metrics across academic years\n",
    "school_performance = (\n",
    "    spark_df\n",
    "    # Group data by school and academic context\n",
    "    .groupBy(\"school_id\",\"school_name\",\"district\",\"academic_year\")\n",
    "    # Calculate average performance indicators for each school per academic year\n",
    "    .agg(\n",
    "        avg(\"avg_exam_score\").alias(\"avg_exam_score\"),\n",
    "        avg(\"pass_percentage\").alias(\"avg_pass_rate\"),\n",
    "        avg(\"attendance_rate\").alias(\"avg_attendance\"),\n",
    "        avg(\"learning_growth_index\").alias(\"avg_learning_growth\"),\n",
    "        avg(\"skill_index\").alias(\"avg_skill_index\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8bf9d27-14bb-4ae5-ace5-114f87f39865",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write the school-level performance metrics to a Delta table\n",
    "school_performance.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"School_Performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78d1e42d-9432-4bb8-bd74-b5d4e5035bb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter schools with high academic performance based on pass rate and attendance thresholds\n",
    "high_performing_schools = school_performance.filter(\n",
    "    # Select schools with an average attendance rate of 85% or higher\n",
    "    (school_performance.avg_pass_rate >= 80) &   \n",
    "    # Select schools with an average attendance rate of 85% or higher\n",
    "    (school_performance.avg_attendance >= 85)\n",
    ")\n",
    "# Write the high-performing schools data to a Delta table\n",
    "high_performing_schools.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"High_Performing_Schools\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "231b8b82-7993-43f2-8faf-352694f781b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "# Aggregate key academic and infrastructure metrics at the school level by academic year\n",
    "school_metrics = (\n",
    "    spark_df\n",
    "    # Group data by school identity, location, and academic year\n",
    "    .groupBy(\"school_id\",\"school_name\",\"district\",\"academic_year\")\n",
    "    # Calculate average values for multiple school performance and access indicators\n",
    "    .agg(\n",
    "        avg(\"attendance_rate\").alias(\"avg_attendance\"),\n",
    "        avg(\"pass_percentage\").alias(\"avg_pass_rate\"),\n",
    "        avg(\"learning_growth_index\").alias(\"avg_learning_growth\"),\n",
    "        avg(\"skill_index\").alias(\"avg_skill_index\"),\n",
    "        avg(\"digital_access_percentage\").alias(\"avg_digital_access\"),\n",
    "        avg(\"remedial_percentage\").alias(\"avg_remedial\")\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc1360d0-cf07-46cd-a96d-1824d0b9ad36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "# Calculate a composite dropout risk score based on multiple weighted academic and access factors\n",
    "dropout_risk = school_metrics.withColumn(\n",
    "    \"dropout_risk_score\",\n",
    "    # Contribution from low attendance (higher risk if attendance is lower)\n",
    "    (1 - col(\"avg_attendance\") / 100) * 0.25 +\n",
    "    # Contribution from low pass rate (higher risk if pass rate is lower)\n",
    "    (1 - col(\"avg_pass_rate\") / 100) * 0.25 +\n",
    "    # Contribution from low learning growth index\n",
    "    (1 - col(\"avg_learning_growth\")) * 0.15 +\n",
    "    # Contribution from low skill index\n",
    "    (1 - col(\"avg_skill_index\") / 100) * 0.15 +\n",
    "    # Contribution from low digital access\n",
    "    (1 - col(\"avg_digital_access\") / 100) * 0.10 +\n",
    "    # Contribution from high remedial requirement\n",
    "    (col(\"avg_remedial\") / 100) * 0.10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b6de5d8-c4b7-43f5-bf26-1cadd7366c25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Assign categorical risk levels based on the calculated dropout risk score\n",
    "dropout_risk = dropout_risk.withColumn(\n",
    "    \"risk_level\",\n",
    "    # Mark schools as High risk if the dropout risk score is 0.35 or above\n",
    "    when(col(\"dropout_risk_score\") >= 0.35, \"High\")\n",
    "    # Mark schools as Medium risk if the score is between 0.20 and 0.35\n",
    "    .when(col(\"dropout_risk_score\") >= 0.20, \"Medium\")\n",
    "    # Mark schools as Low risk if the score is below 0.20\n",
    "    .otherwise(\"Low\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9921ae6-450f-410b-8459-77dce7afdd03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write the dropout risk analysis results to a Delta table\n",
    "dropout_risk.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"Dropout_Risk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7daabe6-6fab-43f8-839b-f9ddadac6a0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg, stddev\n",
    "# Analyze school performance stability using mean and variability metrics\n",
    "school_stability = (\n",
    "    spark_df    \n",
    "    # Group data by school identity and district\n",
    "    .groupBy(\"school_id\",\"school_name\",\"district\")\n",
    "    # Calculate mean and standard deviation for exam scores and pass rates\n",
    "    .agg(\n",
    "        avg(\"avg_exam_score\").alias(\"Exam_mean_score\"),\n",
    "        stddev(\"avg_exam_score\").alias(\"Exam_standard_deviation_score\"),\n",
    "        avg(\"pass_percentage\").alias(\"Mean_Pass_rate\"),\n",
    "        stddev(\"pass_percentage\").alias(\"Pass_rate_standard_deviation\")\n",
    "    )\n",
    ")\n",
    "# Write the school stability analysis to a Delta table\n",
    "school_stability.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"School_Stability\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "331b1712-f5de-47e7-9e89-0335910ac641",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import min, max, first, last\n",
    "# Determine the first and last academic years available for each school\n",
    "yearsBoundaries = (\n",
    "    spark_df\n",
    "    # Group data by school\n",
    "    .groupBy(\"school_id\")\n",
    "    # Identify the earliest and latest academic year for each school\n",
    "    .agg(\n",
    "        min(\"academic_year\").alias(\"First_year\"),\n",
    "        max(\"academic_year\").alias(\"Last_year\")\n",
    "    )\n",
    ")\n",
    "# Analyze improvement or decline in key performance indicators across years\n",
    "schoolTrends = (\n",
    "    # Join the year boundaries back to the main dataset\n",
    "    spark_df\n",
    "    .join(yearsBoundaries, \"school_id\")\n",
    "    # Group data by school identity and location\n",
    "    .groupBy(\"school_id\",\"school_name\",\"district\")\n",
    "    # Calculate changes between the first and last available records\n",
    "    .agg(\n",
    "        (last(\"pass_percentage\") - first(\"pass_percentage\"))\n",
    "            .alias(\"pass_rate_change\"),\n",
    "        (last(\"learning_growth_index\") - first(\"learning_growth_index\"))\n",
    "            .alias(\"learning_growth_change\"),\n",
    "        (last(\"skill_index\") - first(\"skill_index\"))\n",
    "            .alias(\"skill_index_change\")\n",
    "    )\n",
    ")\n",
    "# Write the school improvement vs decline analysis to a Delta table\n",
    "schoolTrends.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"School_Improvement_Vs_Decline\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f9823f6-ba41-433d-a403-3dbfd877ffb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import corr\n",
    "# Analyze the impact of remedial programs on academic performance at the school level\n",
    "remedialImpact = (\n",
    "    spark_df\n",
    "    # Group data by school identity and district\n",
    "    .groupBy(\"school_id\",\"school_name\",\"district\")\n",
    "    # Calculate average remedial participation and performance indicators\n",
    "    .agg(\n",
    "        avg(\"remedial_percentage\").alias(\"avg_remedial\"),\n",
    "        avg(\"pass_percentage\").alias(\"avg_pass_rate\"),\n",
    "        avg(\"learning_growth_index\").alias(\"avg_learning_growth\")\n",
    "    )\n",
    ")\n",
    "# Write the remedial impact analysis to a Delta table\n",
    "remedialImpact.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"Remedial_Impact\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c80c90dc-6701-41dc-8c4b-2a16b906d83c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import max, min\n",
    "# Analyze performance disparity within each district\n",
    "district_gap = (\n",
    "    spark_df    \n",
    "    # Group data by district\n",
    "    .groupBy(\"district\")\n",
    "    # Identify the best and worst school pass rates within each district\n",
    "    .agg(\n",
    "        max(\"pass_percentage\").alias(\"Best_school_pass_rate\"),\n",
    "        min(\"pass_percentage\").alias(\"Worst_school_pass_rate\")\n",
    "    )\n",
    "    # Calculate the performance gap between best and worst schools\n",
    "    .withColumn(\n",
    "        \"performance_gap\",\n",
    "        col(\"Best_school_pass_rate\") - col(\"Worst_school_pass_rate\")\n",
    "    )\n",
    ")\n",
    "# Write the district-level performance gap analysis to a Delta table\n",
    "district_gap.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"District_Performance_Gap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e2ec89c-98fd-4dbe-9579-8d0c47dba664",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Compare enrollment, performance, and access metrics across districts\n",
    "UrbanRuralComparison = (\n",
    "    spark_df\n",
    "    # Group data by district \n",
    "    .groupBy(\"district\")\n",
    "    # Calculate average enrollment, performance, and access indicators\n",
    "    .agg(\n",
    "        avg(\"enrolled_students\").alias(\"avg_enrollment\"),\n",
    "        avg(\"pass_percentage\").alias(\"avg_pass_rate\"),\n",
    "        avg(\"digital_access_percentage\").alias(\"avg_digital_access\"),\n",
    "        avg(\"skill_index\").alias(\"avg_skill_index\")\n",
    "    )\n",
    ")\n",
    "# Write the urbanâ€“rural comparison analysis to a Delta table\n",
    "UrbanRuralComparison.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"Urban_Rural_Comparison\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18041ea3-2543-44cb-83a1-00f13306ae1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Analyze how efficiently educational resources are utilized across districts\n",
    "resourceEfficiency = (\n",
    "    spark_df    \n",
    "    # Group data by district\n",
    "    .groupBy(\"district\")\n",
    "    # Calculate average resource and performance indicators\n",
    "    .agg(\n",
    "        avg(\"student_teacher_ratio\").alias(\"avg_student_teacher_ratio\"),\n",
    "        avg(\"pass_percentage\").alias(\"avg_pass_rate\"),\n",
    "        avg(\"learning_growth_index\").alias(\"avg_learning_growth\")\n",
    "    )\n",
    ")\n",
    "# Write the resource efficiency analysis to a Delta table\n",
    "resourceEfficiency.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"Resource_Efficiency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23c8974e-cc36-40e1-9259-4c21330e5c3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Analyze learning growth trends over time at the district level\n",
    "districtGrowth = (\n",
    "    spark_df    \n",
    "    # Group data by district and academic year to capture yearly growth patterns\n",
    "    .groupBy(\n",
    "        \"district\",\n",
    "        \"academic_year\"\n",
    "    )\n",
    "    # Calculate the average learning growth index for each district-year combination\n",
    "    .agg(\n",
    "        avg(\"learning_growth_index\").alias(\"avg_learning_growth\")\n",
    "    )\n",
    "    # Order results by district and academic year for time-series analysis\n",
    "    .orderBy(\"district\", \"academic_year\")\n",
    ")\n",
    "# Write the district growth momentum analysis to a Delta table\n",
    "districtGrowth.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"District_Growth_Momentum\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcd439d6-e563-429d-95a5-2e31ebf428d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Analyze the relationship between student enrollment and academic performance at the school level\n",
    "EnrollmentvsPerformance = (\n",
    "    spark_df\n",
    "    # Group data by school identity, location, and academic year\n",
    "    .groupBy(\n",
    "        \"school_id\",\n",
    "        \"school_name\",\n",
    "        \"district\",\n",
    "        \"academic_year\"\n",
    "    )\n",
    "    # Calculate average enrollment and pass rate for each school-year combination\n",
    "    .agg(\n",
    "        avg(\"enrolled_students\").alias(\"avg_enrollment\"),\n",
    "        avg(\"pass_percentage\").alias(\"avg_pass_rate\")\n",
    "    )\n",
    ")\n",
    "# Write the enrollment versus performance analysis to a Delta table\n",
    "EnrollmentvsPerformance.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"Enrollment_vs_Performance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "281f9c80-c2a3-49d9-9f20-25a39a613543",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "# Classify schools based on their learning growth trajectory over time\n",
    "learningTrajectory = (\n",
    "    schoolTrends    \n",
    "    # Assign a trajectory type based on change in learning growth index\n",
    "    .withColumn(\n",
    "        \"trajectory_type\",\n",
    "        # Schools with significant positive growth\n",
    "        when(col(\"learning_growth_change\") > 0.10, \"Fast Improver\")\n",
    "        # Schools with moderate positive growth\n",
    "        .when(col(\"learning_growth_change\") > 0.02, \"Slow Improver\")\n",
    "        # Schools showing a decline in learning growth\n",
    "        .when(col(\"learning_growth_change\") < -0.02, \"Declining\")\n",
    "        # Schools with minimal or no change\n",
    "        .otherwise(\"Stagnant\")\n",
    "    )\n",
    ")\n",
    "# Write the learning trajectory classification to a Delta table\n",
    "learningTrajectory.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"Learning_Trajectory\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "816ac4cb-c9d2-4927-9332-db85454b3c7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Aggregate key early warning indicators at the school level\n",
    "earlyWarning = (\n",
    "    spark_df\n",
    "    # Group data by school identity and district\n",
    "    .groupBy(\"school_id\",\"school_name\",\"district\")    \n",
    "    # Calculate average values for attendance, exam participation, and remedial need\n",
    "    .agg(\n",
    "        avg(\"attendance_rate\").alias(\"avg_attendance\"),\n",
    "        avg(\"exam_participation_rate\").alias(\"avg_exam_participation\"),\n",
    "        avg(\"remedial_percentage\").alias(\"avg_remedial\")\n",
    "    )\n",
    ")\n",
    "# Write the early warning indicators to a Delta table\n",
    "earlyWarning.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"Early_Warning_Indicators\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10f42094-0a52-4fe2-86fc-c0f18778309f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Rank Schools using Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f04f257-22cd-466b-9ed8-7c66bb46c0a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import column reference function from PySpark\n",
    "from pyspark.sql.functions import col\n",
    "# Calculate a composite school performance score using weighted indicators\n",
    "schoolScore = (\n",
    "    school_metrics\n",
    "    # Create a weighted school score combining academic and engagement factors\n",
    "    .withColumn(\n",
    "        \"school_score\",\n",
    "        (\n",
    "            # Weight contribution from pass rate\n",
    "            col(\"avg_pass_rate\") * 0.35 +\n",
    "            # Weight contribution from attendance rate\n",
    "            col(\"avg_attendance\") * 0.25 +\n",
    "            # Weight contribution from learning growth (scaled to percentage)\n",
    "            col(\"avg_learning_growth\") * 100 * 0.20 +\n",
    "            # Weight contribution from skill index\n",
    "            col(\"avg_skill_index\") * 0.20\n",
    "        )\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a05f0938-8730-4579-90ae-0891fd88e289",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, rank, lit\n",
    "# Add a dummy column for global ranking\n",
    "schoolScore_rank_base = schoolScore.withColumn(\"global_partition\", lit(1))\n",
    "# Global ranking window (no performance warning)\n",
    "overall_window = (\n",
    "    Window.partitionBy(\"global_partition\")\n",
    "          .orderBy(col(\"school_score\").desc())\n",
    ")\n",
    "# District-wise ranking window (already correct)\n",
    "district_window = (\n",
    "    Window.partitionBy(\"district\")\n",
    "          .orderBy(col(\"school_score\").desc())\n",
    ")\n",
    "# Apply rankings\n",
    "school_ranking = (\n",
    "    schoolScore_rank_base\n",
    "        .withColumn(\"overall_rank\", rank().over(overall_window))\n",
    "        .withColumn(\"district_rank\", rank().over(district_window))\n",
    "        .drop(\"global_partition\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8c30c0e-7ea5-4df2-a018-34b73c4e4f54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "school_ranking.write.format(\"delta\").mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"School_Ranking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc1ba3d0-f67d-4886-b656-8477271d5de1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Machine Learning Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "584192c3-ceee-4632-b4c4-fef374645962",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Select relevant academic, performance, and infrastructure columns for pandas analysis\n",
    "pand = (\n",
    "    # Use the main Spark DataFrame\n",
    "    spark_df\n",
    "    # Select required columns for downstream pandas-based analysis or modeling\n",
    "    .select(\n",
    "        \"school_id\",\n",
    "        \"academic_year\",\n",
    "        \"enrolled_students\",\n",
    "        \"attendance_rate\",\n",
    "        \"pass_percentage\",\n",
    "        \"avg_exam_score\",\n",
    "        \"learning_growth_index\",\n",
    "        \"skill_index\",\n",
    "        \"digital_access_percentage\",\n",
    "        \"scholarship_percentage\",\n",
    "        \"student_teacher_ratio\"\n",
    "    )\n",
    "    # Convert the Spark DataFrame to a pandas DataFrame\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ed3bca0-80ee-4aa3-b3e7-34b4d361e903",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Aggregate school-level yearly information using pandas\n",
    "schoolyear_information = (\n",
    "    # Use the pandas DataFrame converted from Spark\n",
    "    pand\n",
    "    # Group data by school and academic year\n",
    "    .groupby(\n",
    "        [\"school_id\", \"academic_year\"],\n",
    "        as_index=False\n",
    "    )\n",
    "    # Compute yearly aggregates for enrollment, performance, and resource indicators\n",
    "    .agg(\n",
    "        # Total number of enrolled students per school-year\n",
    "        total_enrollment=(\"enrolled_students\", \"sum\"),\n",
    "        # Average attendance rate per school-year\n",
    "        averageattendance=(\"attendance_rate\", \"mean\"),\n",
    "        # Average pass rate per school-year\n",
    "        averagepassrate=(\"pass_percentage\", \"mean\"),    \n",
    "        # Average exam score per school-year\n",
    "        averageexamscore=(\"avg_exam_score\", \"mean\"),\n",
    "        # Average learning growth index per school-year\n",
    "        averagelearninggrowth=(\"learning_growth_index\", \"mean\"),\n",
    "        # Average skill index per school-year\n",
    "        averageskillindex=(\"skill_index\", \"mean\"),\n",
    "        # Average digital access percentage per school-year\n",
    "        averagedigitalaccess=(\"digital_access_percentage\", \"mean\"),\n",
    "        # Average scholarship coverage per school-year\n",
    "        averagescholarship=(\"scholarship_percentage\", \"mean\"),\n",
    "        # Average studentâ€“teacher ratio per school-year\n",
    "        averagestudentteacherratio=(\"student_teacher_ratio\", \"mean\")\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42bb1fc3-8934-437f-bddb-cc2c2e2e2146",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sort the data by school and academic year to ensure correct temporal ordering\n",
    "schoolyear_information = (\n",
    "    schoolyear_information\n",
    "    .sort_values([\"school_id\", \"academic_year\"])\n",
    ")\n",
    "# Create a column containing the previous year's enrollment for each school\n",
    "schoolyear_information[\"prev_enrollment\"] = (\n",
    "    schoolyear_information\n",
    "    .groupby(\"school_id\")[\"total_enrollment\"]\n",
    "    .shift(1)\n",
    ")\n",
    "# Calculate year-over-year enrollment growth for each school\n",
    "schoolyear_information[\"EnrollmentGrowth\"] = (\n",
    "    (schoolyear_information[\"total_enrollment\"] -\n",
    "     schoolyear_information[\"prev_enrollment\"]) /\n",
    "     schoolyear_information[\"prev_enrollment\"]\n",
    ")\n",
    "# Remove rows with missing values created due to the shift operation\n",
    "enrollment = schoolyear_information.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82263f04-bd81-4ab5-8d6a-de3b03d09de4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=4, random_state=40)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(max_depth=4, random_state=40)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=4, random_state=40)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Define the feature set used to predict enrollment growth\n",
    "features = [\n",
    "    \"averageattendance\",\n",
    "    \"averagepassrate\",\n",
    "    \"averageexamscore\",\n",
    "    \"averagelearninggrowth\",\n",
    "    \"averageskillindex\",\n",
    "    \"averagedigitalaccess\",\n",
    "    \"averagescholarship\",\n",
    "    \"averagestudentteacherratio\"\n",
    "]\n",
    "# Create the input feature matrix from the enrollment DataFrame\n",
    "X = enrollment[features]\n",
    "# Define the target variable as year-over-year enrollment growth\n",
    "y = enrollment[\"EnrollmentGrowth\"]\n",
    "# Initialize the Random Forest Regressor with chosen hyperparameters\n",
    "randomforest = RandomForestRegressor(\n",
    "    # Number of decision trees in the forest\n",
    "    n_estimators=100, \n",
    "    # Maximum depth of each tree to control overfitting\n",
    "    max_depth=4,   \n",
    "    # Seed for reproducibility    \n",
    "    random_state=40   \n",
    ")\n",
    "# Train the Random Forest model on the input features and target variable\n",
    "randomforest.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6aeae2a-364c-4785-8f6a-356e2ed73ff7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      feature  importance\n2            averageexamscore   20.044368\n4           averageskillindex   17.230824\n6          averagescholarship   12.950768\n3       averagelearninggrowth   12.731256\n7  averagestudentteacherratio   10.359344\n0           averageattendance    9.509665\n1             averagepassrate    9.103673\n5        averagedigitalaccess    8.070101\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Create a DataFrame to store feature importance values from the trained Random Forest model\n",
    "featureImportance = pd.DataFrame({\n",
    "    \"feature\": features,\n",
    "    \"importance\": randomforest.feature_importances_ * 100\n",
    "})\n",
    "# Sort features by importance in descending order\n",
    "featureImportance = featureImportance.sort_values(\n",
    "    \"importance\",\n",
    "    ascending=False\n",
    ")\n",
    "print(featureImportance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56e9e76a-c32c-4210-a68d-27fafb1b19ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.createDataFrame(featureImportance) \\\n",
    "    .write.format(\"delta\").mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"Enrollment_Feature_Importance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5ba6f68-8219-4086-9817-a7ea91cda2cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert Spark to Pandas\n",
    "inputs = spark_df.select(\n",
    "    \"school_id\",\n",
    "    \"attendance_rate\",\n",
    "    \"pass_percentage\",\n",
    "    \"avg_exam_score\",\n",
    "    \"learning_growth_index\",\n",
    "    \"skill_index\",\n",
    "    \"digital_access_percentage\",\n",
    "    \"remedial_percentage\",\n",
    "    \"exam_participation_rate\",\n",
    "    \"student_teacher_ratio\"\n",
    ").toPandas()\n",
    "# Aggregate to school level\n",
    "schools = (\n",
    "    inputs\n",
    "    .groupby(\"school_id\", as_index=False)\n",
    "    .agg(\n",
    "        averageattendance=(\"attendance_rate\", \"mean\"),\n",
    "        averagepass_rate=(\"pass_percentage\", \"mean\"),\n",
    "        averageexam_score=(\"avg_exam_score\", \"mean\"),\n",
    "        averagelearning_growth=(\"learning_growth_index\", \"mean\"),\n",
    "        averageskill_index=(\"skill_index\", \"mean\"),\n",
    "        averagedigital_access=(\"digital_access_percentage\", \"mean\"),\n",
    "        averageremedial=(\"remedial_percentage\", \"mean\"),\n",
    "        averageexam_participation=(\"exam_participation_rate\", \"mean\"),\n",
    "        averagestudent_teacher_ratio=(\"student_teacher_ratio\", \"mean\")\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78d6c7d2-bd54-4ceb-980a-7727525a2f1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Compute the lower quartilethresholds for key school performance indicators\n",
    "# Attendance cutoff to identify low-attendance schools\n",
    "attendance_cutoff = schools[\"averageattendance\"].quantile(0.25)\n",
    "# Pass rate cutoff to identify low academic success\n",
    "passrate_cutoff = schools[\"averagepass_rate\"].quantile(0.25)\n",
    "# Learning growth cutoff to identify weak learning progression\n",
    "learninggrowth_cutoff = schools[\"averagelearning_growth\"].quantile(0.25)\n",
    "# Skill index cutoff to identify low skill development\n",
    "skillindex_cutoff = schools[\"averageskill_index\"].quantile(0.25)\n",
    "# Digital access cutoff to identify limited technology access\n",
    "digitalaccess_cutoff = schools[\"averagedigital_access\"].quantile(0.25)\n",
    "# Remedial percentage cutoff to identify high remedial dependency\n",
    "remedial_cutoff = schools[\"averageremedial\"].quantile(0.25)\n",
    "# Exam participation cutoff to identify low exam engagement\n",
    "exam_participation = schools[\"averageexam_participation\"].quantile(0.25)\n",
    "# Studentâ€“teacher ratio cutoff to identify high classroom load\n",
    "student_teacher_ratio = schools[\"averagestudent_teacher_ratio\"].quantile(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea339133-47c3-487c-921a-12e1013383c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a binary dropout risk indicator based on multiple low-performance thresholds\n",
    "schools[\"dropout_risk\"] = (\n",
    "    (schools[\"averageattendance\"] <= attendance_cutoff) |    \n",
    "    (schools[\"averagepass_rate\"] <= passrate_cutoff) |\n",
    "    (schools[\"averagelearning_growth\"] <= learninggrowth_cutoff) |\n",
    "    (schools[\"averageskill_index\"] <= skillindex_cutoff) |\n",
    "    (schools[\"averagedigital_access\"] <= digitalaccess_cutoff) |\n",
    "    (schools[\"averageremedial\"] <= remedial_cutoff) |\n",
    "    (schools[\"averageexam_participation\"] <= exam_participation) |\n",
    "    (schools[\"averagestudent_teacher_ratio\"] <= student_teacher_ratio)\n",
    ").astype(int)   # Convert boolean values to binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f13126ab-e67e-421c-88b6-a2d2299ba049",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=5, random_state=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(max_depth=5, random_state=4)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=5, random_state=4)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Define the feature set used to predict dropout risk\n",
    "features = [\n",
    "    \"averageattendance\",\n",
    "    \"averagepass_rate\",\n",
    "    \"averageexam_score\",\n",
    "    \"averagelearning_growth\",\n",
    "    \"averageskill_index\",\n",
    "    \"averagedigital_access\",\n",
    "    \"averageremedial\",\n",
    "    \"averageexam_participation\",\n",
    "    \"averagestudent_teacher_ratio\"\n",
    "]\n",
    "# Create the input feature matrix from the schools DataFrame\n",
    "X = schools[features]\n",
    "\n",
    "# Define the target variable indicating dropout risk\n",
    "y = schools[\"dropout_risk\"]\n",
    "# Initialize the Random Forest Classifier with selected hyperparameters\n",
    "randomforest = RandomForestClassifier(\n",
    "    # Number of trees in the forest\n",
    "    n_estimators=100, \n",
    "    # Maximum depth to control model complexity \n",
    "    max_depth=5, \n",
    "    # Seed for reproducibility      \n",
    "    random_state=4    \n",
    ")\n",
    "# Train the Random Forest classifier on the input features and target labels\n",
    "randomforest.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84aa9af4-2162-41d5-bc21-51612feaf978",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        feature  importance\n0             averageattendance   21.858281\n6               averageremedial   16.040056\n8  averagestudent_teacher_ratio   10.670944\n1              averagepass_rate   10.181498\n4            averageskill_index   10.059705\n3        averagelearning_growth    9.010947\n2             averageexam_score    8.665146\n7     averageexam_participation    7.054047\n5         averagedigital_access    6.459375\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Create a DataFrame to display feature importance from the trained dropout risk model\n",
    "dropoutfeature = pd.DataFrame({\n",
    "    # Feature names used in the classification model\n",
    "    \"feature\": features,\n",
    "    # Corresponding importance scores converted to percentages\n",
    "    \"importance\": randomforest.feature_importances_ * 100\n",
    "})\n",
    "# Sort features by importance in descending order\n",
    "dropoutfeature = dropoutfeature.sort_values(\n",
    "    \"importance\",\n",
    "    ascending=False\n",
    ")\n",
    "# Display the feature importance table\n",
    "print(dropoutfeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a10deaa-b3a1-443e-a1ec-f2f103c08f57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.createDataFrame(dropoutfeature) \\\n",
    "    .write.format(\"delta\").mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"Dropout_Features\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Data Analytics",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}