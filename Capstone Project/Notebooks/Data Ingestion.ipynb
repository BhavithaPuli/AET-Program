{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed1b996b-2c2d-4e18-8c30-d4c2476cea3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c9ebc25-2380-42c7-88dd-636338b2cf47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "raw = \"/Volumes/workspace/default/capstone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23c09916-0a08-4bb5-81bc-bd21b5ae4c24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def csvFiles(directory_path):\n",
    "    # Lists all CSV files from the given directory\n",
    "    try:\n",
    "        files = os.listdir(directory_path)\n",
    "        csv_files = [\n",
    "            os.path.join(directory_path, file)\n",
    "            for file in files\n",
    "            if file.endswith(\".csv\")\n",
    "        ]\n",
    "        return csv_files\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Failed to list files from directory: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25005ce4-910c-4639-a77f-15bcb6170d41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def combineFiles(file_paths):\n",
    "    # Reads multiple CSV files and combines them into one DataFrame\n",
    "    dataframes = []\n",
    "    for path in file_paths:\n",
    "        try:\n",
    "            df = pd.read_csv(path)\n",
    "            df[\"source_file\"] = os.path.basename(path)\n",
    "            dataframes.append(df)\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error reading file {path}: {e}\")\n",
    "    if not dataframes:\n",
    "        raise ValueError(\"No dataframes were created during ingestion\")\n",
    "    return pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d4a88d1-3808-43da-b864-84dc8e75635b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def validateData(df):\n",
    "    # Performs structural validation on ingested data\n",
    "    if df.empty:\n",
    "        raise ValueError(\"Ingested dataset is empty\")\n",
    "    core_columns = [\"school_id\",\"academic_year\",\"district\",\"grade\", \"gender\"]\n",
    "    missing_columns = [col for col in core_columns if col not in df.columns]\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Missing core columns: {missing_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42cbda43-d8db-45d0-b74b-b6698f7831b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def StudentPerformanceColumns(df):\n",
    "    # Adds raw student performance indicators during ingestion\n",
    "    np.random.seed(40)\n",
    "    df[\"median_exam_score\"] = np.random.uniform(55, 95, len(df)).round(1)\n",
    "    df[\"pass_percentage\"] = np.random.uniform(65, 98, len(df)).round(1)\n",
    "    df[\"fail_percentage\"] = (100 - df[\"pass_percentage\"]).round(1)\n",
    "    df[\"distinction_percentage\"] = np.random.uniform(5, 35, len(df)).round(1)\n",
    "    df[\"attendance_rate\"] = np.random.uniform(70, 100, len(df)).round(1)\n",
    "    df[\"avg_internal_score\"] = np.random.uniform(50, 90, len(df)).round(1)\n",
    "    df[\"exam_participation_rate\"] = np.random.uniform(75, 100, len(df)).round(1)\n",
    "    df[\"remedial_percentage\"] = np.random.uniform(5, 30, len(df)).round(1)\n",
    "    df[\"student_teacher_ratio\"] = np.random.uniform(15, 50, len(df)).round(1)\n",
    "    df[\"digital_access_percentage\"] = np.random.uniform(30, 95, len(df)).round(1)\n",
    "    df[\"scholarship_percentage\"] = np.random.uniform(10, 65, len(df)).round(1)\n",
    "    df[\"learning_growth_index\"] = np.random.uniform(0.1, 0.9, len(df)).round(2)\n",
    "    df[\"subject_pass_rate\"] = np.random.uniform(65, 98, len(df)).round(1)\n",
    "    df[\"skill_index\"] = np.random.uniform(35, 95, len(df)).round(1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4aa585c-0aed-477a-b387-6dd787a5ac7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def ingestionEnrollment(raw_dir):\n",
    "    # Orchestrates raw enrollment data ingestion\n",
    "    csv_files = csvFiles(raw_dir)\n",
    "    if not csv_files:\n",
    "        raise FileNotFoundError(\"No CSV files found in data directory\")\n",
    "    rawData=combineFiles(csv_files)\n",
    "    rawData=StudentPerformanceColumns(rawData)\n",
    "    validateData(rawData)\n",
    "    return rawData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddf51d66-9f34-42bd-9d3d-186788accad4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data ingestion completed successfully\nTotal records ingested: 41700\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    enrollmentData = ingestionEnrollment(raw)\n",
    "    print(\"Data ingestion completed successfully\")\n",
    "    print(\"Total records ingested:\", enrollmentData.shape[0])\n",
    "    enrollmentData.head()\n",
    "except Exception as e:\n",
    "    print(\"Data ingestion failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac63b894-24a1-4865-8111-80661b6640d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def ingestedFiles(df):\n",
    "    # Returns unique file names that were ingested\n",
    "    return df[\"source_file\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d23f75fa-2c4a-4158-bf69-080e24076a53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files successfully ingested:\nenrollment_2020.csv\nenrollment_2021.csv\nenrollment_2022.csv\nenrollment_2023.csv\nenrollment_2024.csv\n"
     ]
    }
   ],
   "source": [
    "ingested_files = ingestedFiles(enrollmentData)\n",
    "print(\"Files successfully ingested:\")\n",
    "for file in ingested_files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2628b62-0337-40d9-bf14-4a5e51151b9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def combinedData(df, table_name):\n",
    "    #Saves the combined enrollment data as a Delta table.\n",
    "    try:\n",
    "        (\n",
    "            df.write\n",
    "              .format(\"delta\")\n",
    "              .mode(\"append\")\n",
    "              .saveAsTable(table_name)\n",
    "        )\n",
    "        print(f\"Combined raw data saved as Delta table: {table_name}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Failed to save combined raw data as Delta table: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09a0c648-7b81-49a7-a77e-12dba9d486ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS school_enrollment_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebf2f3c1-d922-42cf-a667-3abeb6d46596",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame as SparkDataFrame\n",
    "import pandas as pd\n",
    "# Ensure enrollmentData is a Spark DataFrame before writing to Delta\n",
    "if isinstance(enrollmentData, pd.DataFrame):\n",
    "    enrollmentData = spark.createDataFrame(enrollmentData)\n",
    "elif not isinstance(enrollmentData, SparkDataFrame):\n",
    "    raise TypeError(\"enrollmentData must be either a Pandas or Spark DataFrame\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da4344dd-b615-42fd-a10f-4132cd7e3624",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined raw data saved as Delta table: combined_school_enrollment\n"
     ]
    }
   ],
   "source": [
    "combined_df = combinedData(\n",
    "    enrollmentData,\n",
    "    \"combined_school_enrollment\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Data Ingestion",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}